{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple, defaultdict\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from tenacity import retry, stop_after_attempt\n",
    "import simplejson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,ja;q=0.6\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": \"https://www.google.com.tw/\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) \"\\\n",
    "                  \"Chrome/69.0.3497.92 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_page_to_url(issue, page_num):\n",
    "    url_format = 'https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/' \\\n",
    "                 'issue/{}?pageNum={}'\n",
    "    return url_format.format(issue, page_num)\n",
    "\n",
    "def get_website_url(suffix):\n",
    "    prefix = 'https://www.cambridge.org{}'\n",
    "    return prefix.format(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(3))\n",
    "def get_bsObj(url):\n",
    "    req = session.get(url, headers=headers)\n",
    "    bsObj = BS(req.text, \"html.parser\")\n",
    "    return bsObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references_from_url(url):\n",
    "    \n",
    "    req = session.get(url, headers=headers)\n",
    "    art_bsObj = BS(req.text, \"html.parser\")\n",
    "    \n",
    "    reference_infos = []\n",
    "    for ref in art_bsObj.find_all('span', class_='mixed-citation journal'):\n",
    "        authors = []\n",
    "        for name in ref.find_all('span', class_='name'):\n",
    "            surname = name.find('span', class_='surname')\n",
    "            surname = surname.text if surname else None\n",
    "            \n",
    "            given_names = name.find('span', class_='given-names')\n",
    "            given_names = given_names.text if given_names else None\n",
    "            \n",
    "            detailed_name = DetailedName(surname=surname, given_names=given_names)\n",
    "            authors.append(detailed_name)\n",
    "\n",
    "        year = ref.find('span', class_='year')\n",
    "        year = year.text if year else None\n",
    "        \n",
    "        title = ref.find('span', class_='article-title')\n",
    "        title = title.text if title else None\n",
    "        \n",
    "        source = ref.find('span', class_='source')\n",
    "        source = source.text if source else None\n",
    "\n",
    "        reference_info = ReferenceInfo(authors=authors,\n",
    "                                       year=year,\n",
    "                                       title=title,\n",
    "                                       source=source)\n",
    "        reference_infos.append(reference_info)\n",
    "    return reference_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArticleInfo = namedtuple('ArticleInfo', ['authors', 'title', 'url', 'article_type', 'references'])\n",
    "AuthorInfo = namedtuple('Author', ['author_name', 'url'])\n",
    "DetailedName = namedtuple('DetailedName', ['surname', 'given_names'])\n",
    "ReferenceInfo = namedtuple('ReferenceInfo', ['authors', 'year', 'title', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_infos_from_issue(issue):\n",
    "    article_infos = []\n",
    "    for page_num in itertools.count(start=1):\n",
    "\n",
    "        page = get_bsObj(issue_page_to_url(issue, page_num))\n",
    "\n",
    "        heading_banner = page.find('h4', class_='journal-article-listing-type heading_12 margin-bottom')\n",
    "        if not heading_banner:\n",
    "            break\n",
    "        assert heading_banner['class'] == ['journal-article-listing-type', 'heading_12', 'margin-bottom']\n",
    "\n",
    "        now_type = heading_banner.text\n",
    "        print('\\n', now_type, end='\\n\\n')\n",
    "\n",
    "        for idx, item in enumerate(heading_banner.find_next_siblings()):\n",
    "            link = item.find('a', class_='part-link')\n",
    "            authors = item.find('li', class_='author')\n",
    "            if link and authors:\n",
    "                author_infos = []\n",
    "                for author_objs in authors.find_all('a'):\n",
    "                    author_name = author_objs.text\n",
    "                    author_url = author_objs['href']\n",
    "                    author_infos.append(AuthorInfo(author_name=author_name, url=author_url))\n",
    "\n",
    "                title = link.text.strip()\n",
    "                url = get_website_url(link['href'])\n",
    "                references = get_references_from_url(url)\n",
    "                info = ArticleInfo(authors=author_infos,\n",
    "                                   title=title,\n",
    "                                   url=url,\n",
    "                                   article_type=now_type,\n",
    "                                   references=references)\n",
    "                article_infos.append(info)\n",
    "\n",
    "                print(title)\n",
    "\n",
    "            else:\n",
    "                assert item['class'] == ['journal-article-listing-type', 'heading_12', 'margin-bottom']\n",
    "                now_type = item.text\n",
    "                print('\\n', now_type, end='\\n\\n')\n",
    "    return article_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_list_to_trees(articles, head='Target Article', children='Open Peer Commentary'):\n",
    "    head_to_children = defaultdict(dict)\n",
    "    \n",
    "    head_article = None\n",
    "    for article in articles:\n",
    "        if article['article_type'] == head:\n",
    "            \n",
    "            _article = deepcopy(article)\n",
    "            title = _article.pop('title', None)\n",
    "            head_to_children[title] = _article\n",
    "            head_to_children[title]['commentaries'] = []\n",
    "            head_article = title\n",
    "        \n",
    "        elif article['article_type'] == children:\n",
    "            \n",
    "            head_to_children[head_article]['commentaries'].append(article)\n",
    "    \n",
    "    return head_to_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('articles/articles.json'):\n",
    "    year_to_issue = {2019: '1F6CCA8ABB7741DAFF471736F58BA234',\n",
    "                     2018: '03CCA4BACDCFC590CB9C8B2983DC5AB3',\n",
    "                     2017: '7FEFD73781C19F5897B0CE53B13BD467',\n",
    "                     2016: '0009F28DF9EDDEA8BE73402A78E14895',\n",
    "                     2015: 'F5C34D98D365BFA85AE25C045B2E7322'}\n",
    "\n",
    "    year_to_articles = {}\n",
    "    for year, issue in year_to_issue.items():\n",
    "        article_infos = get_article_infos_from_issue(issue)\n",
    "        year_to_articles[year] = article_infos\n",
    "\n",
    "    with open('articles/articles.json', 'w') as f:\n",
    "        json.dump(year_to_articles, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    with open('articles/articles.json', 'r') as f:\n",
    "        json_type_ytoa = json.load(f)\n",
    "    for year, articles in json_type_ytoa.items():\n",
    "        trees = transform_list_to_trees(articles)\n",
    "        with open('articles/{}_articles.json'.format(year), 'w') as f:\n",
    "            json.dump(trees, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
